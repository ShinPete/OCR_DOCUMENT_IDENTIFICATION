{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance\n",
    "import re\n",
    "import os\n",
    "import os, json, joblib\n",
    "from datetime import datetime\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "print(np.__version__)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.categorizer import preprocessing\n",
    "preprocessing.main()"
   ],
   "id": "b31135c25f584f1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def clean_text(raw_text):\n",
    "    # Collapse whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", raw_text).strip()\n",
    "\n",
    "    # Remove common header/footer artifacts\n",
    "    text = re.sub(r\"Page\\s*\\d+|\\d+\\s*/\\s*\\d+\", \"\", text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Strict zero replacement (only in CAPS words)\n",
    "    text = re.sub(r\"\\b([A-Z]*?)0([A-Z]*?)\\b\", lambda m: m.group(0).replace(\"0\", \"O\"), text)\n",
    "    \n",
    "    # Looser one replacement (fixes Th1s â†’ This)\n",
    "    text = re.sub(r\"\\b(\\w*?)1(\\w*?)\\b\", lambda m: m.group(0).replace(\"1\", \"l\"), text)\n",
    "\n",
    "    # Lowercase for consistency\n",
    "    text = text.lower()\n",
    "\n",
    "    # Optional: remove punctuation\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "\n",
    "    return text\n"
   ],
   "id": "4e2916441bbbc85b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def preprocess_image(img):\n",
    "    img_rgb = img.convert(\"RGB\")\n",
    "    enhancer = ImageEnhance.Contrast(img_rgb)\n",
    "    img_contrast = enhancer.enhance(2.0)\n",
    "    return img_contrast.convert(\"L\").point(lambda x: 0 if x < 128 else 255, \"1\")"
   ],
   "id": "bc3da661744a8f4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compare_distributions(full_df, list_of_dfs, column, tolerance=1):\n",
    "    true_pct = full_df[column].value_counts(normalize=True)*100\n",
    "    labels = true_pct.index\n",
    "    results = {}\n",
    "    for name, df in list_of_dfs:\n",
    "        df_pct = df[column].value_counts(normalize=True)*100\n",
    "        df_pct = df_pct.reindex(labels, fill_value=0,)\n",
    "        diff = (np.abs(true_pct - df_pct))\n",
    "        bad = diff[diff > tolerance]\n",
    "        ok = (diff<=tolerance).all()\n",
    "        if ok:\n",
    "            print (f\"âœ… Distributions are similar full vs {name}\")\n",
    "            \n",
    "        else:\n",
    "            print (f\"ðŸš¨ Distributions from {name} are more than {tolerance}% \"\n",
    "                    f\"different from full dataset {bad.index} with differences {bad.values}\")\n",
    "        results[name] = {'ok': bool(ok),\n",
    "                        'max_drift': float(diff.max()), \n",
    "                        'bad_labels': bad.index.tolist()}\n",
    "    return results"
   ],
   "id": "f6ed17772c2d6dd1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "print(\"CWD:\", Path.cwd())\n",
    "img_dir = Path(\"data/raw/images/Training\")\n",
    "print(\"Looking for:\", img_dir.resolve())\n",
    "print(\"Exists?\", img_dir.exists())"
   ],
   "id": "c0bc9e2d1b705683",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import os, pandas as pd\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "file_types = ['budget', 'email', 'letter', 'invoice']\n",
    "cols = ['filename', 'type', 'text']\n",
    "\n",
    "img_dir = Path(r\"C:\\Users\\abajp\\PycharmProjects\\BofAOCRProject\\data\\raw\\images\\Training\")\n",
    "processed_dir = Path(r\"C:\\Users\\abajp\\PycharmProjects\\BofAOCRProject\\data\\processed\")\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# img_dir       = Path(\"data/raw/images/Training\")\n",
    "# processed_dir = Path(\"data/processed\")\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "out_path = processed_dir / \"output.csv\"\n",
    "\n",
    "# load processed filenames once (fast: read only that column)\n",
    "processed = set()\n",
    "if out_path.exists():\n",
    "    processed = set(pd.read_csv(out_path, usecols=['filename'])['filename'])\n",
    "\n",
    "for name in os.listdir(img_dir):\n",
    "    path = img_dir / name\n",
    "    if not path.is_file():\n",
    "        continue\n",
    "\n",
    "    match = next((w for w in file_types if w in name.lower()), None)\n",
    "    if not match:\n",
    "        continue\n",
    "    if name in processed:\n",
    "        continue\n",
    "\n",
    "    with Image.open(path) as img:\n",
    "        pre_img = preprocess_image(img)\n",
    "        text = clean_text(pytesseract.image_to_string(pre_img))\n",
    "\n",
    "    # append only the new row\n",
    "    new_df = pd.DataFrame([[name, match, text]], columns=cols)\n",
    "    new_df.to_csv(out_path, mode='a', index=False, header=not out_path.exists())\n",
    "    processed.add(name)"
   ],
   "id": "ab43756552b57949",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# files = os.listdir(\"data/raw/images/Training\")\n",
    "# file_types = ['budget', 'email', 'letter', 'invoice']\n",
    "# cols = ['filename', 'type', 'text']\n",
    "# from pathlib import Path\n",
    "# img_dir = Path(\"data/raw/images/Training\")\n",
    "# processed_dir = Path(\"data/processed\")\n",
    "# \n",
    "# contents = []\n",
    "# file_dict = {}\n",
    "# output_file = \"output.csv\"\n",
    "# \n",
    "# if not os.path.exists(output_file):\n",
    "#     print(\"ðŸš¨ CSV does not exist, creating blank one...\")\n",
    "#     df = pd.DataFrame(columns=cols)\n",
    "#     df.to_csv(output_file, index=False)  # Create blank CSV with header\n",
    "# else:\n",
    "#     print(\"âœ… CSV exists already\")\n",
    "#     df = pd.read_csv(output_file)\n",
    "# \n",
    "# for name in os.listdir(img_dir):\n",
    "#     path = img_dir/name\n",
    "#     match = next((word for word in file_types if word.lower() in name.lower()), None)\n",
    "#     if match:\n",
    "#         print(f\"{name}:{match}\")\n",
    "#     processed_files = set(df['filename'])\n",
    "#     if path in processed_files:\n",
    "#         print(f\"{name} already in df\")\n",
    "#         continue\n",
    "#     file_dict.update({path:match})\n",
    "#     with Image.open(path) as img:\n",
    "#         pre_img = preprocess_image(img)\n",
    "#         text = pytesseract.image_to_string(pre_img)\n",
    "#         # text = pytesseract.image_to_string(Image.open(f\"Training_half/{i}\"))\n",
    "#         text = clean_text(text)   \n",
    "#         # contents.append(text)\n",
    "#         new_df = pd.DataFrame([[path, match, text]], columns = cols)\n",
    "#         df = pd.concat([df, new_df], ignore_index=True)\n",
    "#         if not os.path.exists(\"output.csv\"):\n",
    "#             df.to_csv(f\"{processed_dir}/output.csv\", index=False)  # Write with header\n",
    "#         else:\n",
    "#             df.to_csv(f\"{processed_dir}/output.csv\", mode=\"a\", index=False, header=False)\n",
    "#         \n"
   ],
   "id": "70a166ce1153a215",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save a quick look at the nulls\n",
    "df = pd.read_csv(r'C:\\Users\\abajp\\PycharmProjects\\BofAOCRProject\\data\\processed\\output.csv')\n",
    "nulls = df[df.isna().any(axis=1)]\n",
    "nulls.to_csv(\"null_rows_snapshot.csv\", index=False)\n",
    "\n",
    "# Drop nulls & empty strings in core columns\n",
    "df = df.dropna(subset=[\"text\", \"type\"])\n",
    "df = df[df[\"text\"].str.strip() != \"\"]"
   ],
   "id": "b5027e70d54c7a50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_val, test = train_test_split(df, test_size=0.1, random_state=42, stratify=df['type'])\n",
    "train, val = train_test_split(train_val, test_size=0.09, random_state=42, stratify=train_val['type'])"
   ],
   "id": "2a541bf18c1d4109",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_val_pct = train_val.value_counts('type')/len(train_val)*100\n",
    "test_val_pct = test.value_counts('type')/len(test)*100\n",
    "diff = train_val_pct - test_val_pct\n",
    "diff"
   ],
   "id": "5ea87f388dd5b23f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results = compare_distributions(df, [('train', train), ('val', val), ('test', test)], 'type')\n",
    "results"
   ],
   "id": "10dfb17ecbaa09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train.to_csv(\"../data/processed/datasets/v1/train.csv\", index=False)\n",
    "val.to_csv(\"../data/processed/datasets/v1/validation.csv\", index=False)\n",
    "test.to_csv(\"../data/processed/datasets/v1/test.csv\", index=False)"
   ],
   "id": "945bd9b04a2731da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=50000, min_df=2, sublinear_tf=True)\n",
    "X_train = vectorizer.fit_transform(train['text'].astype(str))\n",
    "X_va = vectorizer.transform(val['text'].astype(str))"
   ],
   "id": "1b816f5cf1d65219",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "codes = {'letter':0, 'budget':1, 'invoice':2, 'email':3}\n",
    "\n",
    "y_train = train['type']\n",
    "y_va = val['type']\n",
    "y_train = y_train.map(codes)\n",
    "y_va =  y_va.map(codes)"
   ],
   "id": "8eb8347fb2204a35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# train logreg model and show performance of model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "clf = LogisticRegression(solver='liblinear', max_iter=2000, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "preds = clf.predict(X_va)\n",
    "print(classification_report(y_va, preds, target_names=codes.keys()))"
   ],
   "id": "4360c0b5b471497d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c72908022914840",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
